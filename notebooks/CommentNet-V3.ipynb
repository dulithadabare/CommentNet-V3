{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CommentNet-V3 \n",
    "\n",
    "Welcome to the version 3 of CommentNet!\n",
    "\n",
    "First let's import the relevant packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Bidirectional, Concatenate, Dot, RepeatVector\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "import keras.backend as K\n",
    "import coremltools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's process the data set.\n",
    "\n",
    "We will process the data set and create a new data set by removing punctuation and trimming the lines in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_list_with_labels, output='../data/data_set.txt', output_label = '../data/labels.txt'):\n",
    "    phrase = []\n",
    "    emoji = []\n",
    "\n",
    "    with open (output, 'w') as output_file, open(output_label, 'w') as label_file:\n",
    "        \n",
    "        for filename, label in file_list_with_labels:\n",
    "            print('Processing file: ', filename)\n",
    "            with open (filename) as f:\n",
    "                  for line in f:\n",
    "                    line = line.strip()\n",
    "                    if len(line)>0:\n",
    "                        table = str.maketrans({key: None for key in string.punctuation})\n",
    "                        line = line.translate(table)\n",
    "                        output_file.write(line + '\\r\\n')\n",
    "                        label_file.write(label + '\\r\\n')\n",
    "                        phrase.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set files are in 3 separate sets of files.\n",
    "\n",
    "- troll data set and it's labels\n",
    "- constructive data set and it's labels\n",
    "- positive data set and it's labels\n",
    "\n",
    "We will process these 3 separate data sets and create one combined dataset and label set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list_with_labels = []\n",
    "file_list_with_labels.append(('../data/troll.txt', '1'))\n",
    "file_list_with_labels.append(('../data/constructive.txt', '0'))\n",
    "file_list_with_labels.append(('../data/positive.txt', '0'))\n",
    "process_data(file_list_with_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, it's time to load the GloVe word embedding files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f, open('../data/glove_word_index.txt', 'w') as word_index_file:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        word_index = []\n",
    "        for w in sorted(words):\n",
    "            word_index.append(w + ' ' + str(i))\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "        \n",
    "        for line in word_index:\n",
    "            word_index_file.write(line + '\\n')\n",
    "    return words_to_index, index_to_words, word_to_vec_map, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map, unknown_word_index = read_glove_vecs('../../../CommentNetData/glove.6B/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will also read in a custom word embedding to be used for unkown word tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_unknown_vecs(unknown_file):\n",
    "    \n",
    "    unknown_vector = None\n",
    "    \n",
    "    with open(unknown_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            unknown_vector = np.array(line[0:], dtype=np.float64)\n",
    "    \n",
    "    print('Unknown word vector is', unknown_vector.shape)\n",
    "\n",
    "    return unknown_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unkown_word_vector = read_unknown_vecs('../data/unknown_word_vector.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"ea\"\n",
    "index = 18\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "print(\"the\", str(index) + \"th word in the vocabulary is\", index_to_word[index])\n",
    "print(unknown_word_index)\n",
    "print(word_to_vec_map[word].reshape(1, -1).shape)\n",
    "cosine_similarity(word_to_vec_map[\"bethesda\"].reshape(1, -1), word_to_vec_map[\"ea\"].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load the data set and label set we processed in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_processed_data(data_set = '../data/data_set.txt', labels = '../data/labels.txt'):\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    with open(data_set) as data_file:\n",
    "        for line in data_file:\n",
    "            line = line.strip()\n",
    "            if len(line) > 0:\n",
    "                X.append(line)\n",
    "    \n",
    "    with open(labels) as label_file:\n",
    "        for line in label_file:\n",
    "            line = line.strip()\n",
    "            if len(line) > 0:\n",
    "                Y.append(line)\n",
    "                \n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y, dtype=int)\n",
    "    \n",
    "    return X, Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = read_processed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X : ', len(X))\n",
    "print('Y : ', len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's shuffle the data set to mix the positive and negative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = shuffle(X, Y, random_state=0)\n",
    "print(X[len(X) - 1], Y[len(Y) - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to find the maximum word count in a sentence in the data set. This value will be used for the masking operation in creating the word indices and will be used to determine the number of time steps in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_len(X):\n",
    "    \n",
    "    max_len = 0\n",
    "    max_line = None\n",
    "    max_array = []\n",
    "    \n",
    "    \n",
    "    for line in X:\n",
    "        sentence_words =line.lower().split()\n",
    "        if len(sentence_words) > max_len:\n",
    "            max_len = len(sentence_words)\n",
    "            max_line = line \n",
    "            max_array = sentence_words\n",
    "    \n",
    "    print ('Max length is ', max_len)\n",
    "    print(max_line)\n",
    "    print(max_array)\n",
    "    \n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = find_max_len(X)\n",
    "Tx = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_dev_test(X, Y, split):\n",
    "    \n",
    "    X, Y = shuffle(X, Y)\n",
    "    \n",
    "    mode = split[0]\n",
    "    \n",
    "    if mode == 'tt':\n",
    "        train_size, test_size = split[1]\n",
    "        \n",
    "        X_train = X[:train_size]\n",
    "        Y_train = Y[:train_size]\n",
    "    \n",
    "        X_test = X[train_size:]\n",
    "        Y_test = Y[train_size:]\n",
    "        \n",
    "        print('Size of test set : ', len(X_train))\n",
    "        print('Size of train set : ', len(X_test))\n",
    "    \n",
    "        result = (X_train, Y_train, X_test, Y_test)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        train_size, dev_size, test_size = split[1]\n",
    "        \n",
    "        X_train = X[:train_size]\n",
    "        Y_train = Y[:train_size]\n",
    "    \n",
    "        X_dev = X[train_size:train_size + dev_size]\n",
    "        Y_dev = Y[train_size:train_size + dev_size]\n",
    "    \n",
    "        X_test = X[train_size + dev_size:]\n",
    "        Y_test = Y[train_size + dev_size:]\n",
    "        \n",
    "        print('Size of test set : ', len(X_train))\n",
    "        print('Size of dev set : ', len(X_dev))\n",
    "        print('Size of train set : ', len(X_test))\n",
    "    \n",
    "        result = (X_train, Y_train, X_dev, Y_dev, X_test, Y_test)\n",
    "\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_dev, Y_dev, X_test, Y_test = create_train_dev_test(X, Y, ['tvt', (100, 25, 25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[len(X_train) - 1], Y_train[len(Y_train) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = create_train_dev_test(X, Y, ['tt', (100, 50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the function to turn the sentences of the data set into word indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len, unknown_word_index):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m):                               # loop over training examples\n",
    "        \n",
    "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
    "        sentence_words =X[i].lower().split()\n",
    "        \n",
    "        # Initialize j to 0\n",
    "        j = 0\n",
    "        \n",
    "        # Loop over the words of sentence_words\n",
    "        for w in sentence_words:\n",
    "            # Set the (i,j)th entry of X_indices to the index of the correct word.\n",
    "            if w in word_to_index:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "                # Increment j to j + 1\n",
    "                j = j + 1\n",
    "            else:\n",
    "                X_indices[i, j] = unknown_word_index\n",
    "                j = j + 1\n",
    "            \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to feed our pre-trained word encodings into the Keras embedding layer. This function will take care of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index, unkown_word_vector, unknown_word_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_len = unknown_word_index + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "    \n",
    "    emb_matrix[unknown_word_index, :] = unkown_word_vector\n",
    "\n",
    "    # Define Keras embedding layer with the correct output/input sizes, make it non-trainable. Use Embedding(...). Make sure to set trainable=False. \n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define custom softmax function to be used in the Attention mechanism's alpha calculation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, axis=1):\n",
    "    \"\"\"Softmax activation function.\n",
    "    # Arguments\n",
    "        x : Tensor.\n",
    "        axis: Integer, axis along which the softmax normalization is applied.\n",
    "    # Returns\n",
    "        Tensor, output of softmax transformation.\n",
    "    # Raises\n",
    "        ValueError: In case `dim(x) == 1`.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define global variables for the attention step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are nor using the custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function to calculate the context for the each step in the final Bi-LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" (≈ 1 line)\n",
    "    s_prev = repeator(s_prev)\n",
    "    # Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)\n",
    "    concat = concatenator([a, s_prev])\n",
    "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e. (≈1 lines)\n",
    "    e = densor1(concat)\n",
    "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies. (≈1 lines)\n",
    "    energies = densor2(e)\n",
    "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" (≈ 1 line)\n",
    "    alphas = activator(energies)\n",
    "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)\n",
    "    context = dotor([alphas, a])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the necessary parts, let's create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CommentNet(input_shape, word_to_vec_map, word_to_index, unkown_word_vector, unknown_word_index):\n",
    "    \"\"\"\n",
    "    Function creatiDabareng the Emojify-v2 model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
    "    sentence_indices = Input(shape = input_shape, dtype = 'int32')\n",
    "    \n",
    "    # Create the embedding layer pretrained with GloVe Vectors (≈1 line)\n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index, unkown_word_vector, unknown_word_index)\n",
    "    \n",
    "    # Propagate sentence_indices through your embedding layer, you get back the embeddings\n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    \n",
    "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a batch of sequences.\n",
    "    a = Bidirectional(LSTM(128, return_sequences = True), merge_mode = 'ave')(embeddings)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    #X = Dropout(rate = 0.5)(X)\n",
    "    \n",
    "    s0 = Input(shape=(128,), name='s0')\n",
    "    c0 = Input(shape=(128,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    post_attention_Bi_LSTM_cell = LSTM(128, return_state = True)\n",
    "    \n",
    "    for t in range(Tx):\n",
    "        \n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        s, _, c = post_attention_Bi_LSTM_cell(context, initial_state = [s, c])\n",
    "        \n",
    "    \n",
    "    # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "    # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "    \n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(rate = 0.5)(s)\n",
    "    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs = [sentence_indices, s0, c0], outputs = X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CommentNet((max_len,), word_to_vec_map, word_to_index, unkown_word_vector, unknown_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 54)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 54, 50)       20000100    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 54, 128)      183296      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 54, 128)      0           s0[0][0]                         \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 lstm_2[2][0]                     \n",
      "                                                                 lstm_2[3][0]                     \n",
      "                                                                 lstm_2[4][0]                     \n",
      "                                                                 lstm_2[5][0]                     \n",
      "                                                                 lstm_2[6][0]                     \n",
      "                                                                 lstm_2[7][0]                     \n",
      "                                                                 lstm_2[8][0]                     \n",
      "                                                                 lstm_2[9][0]                     \n",
      "                                                                 lstm_2[10][0]                    \n",
      "                                                                 lstm_2[11][0]                    \n",
      "                                                                 lstm_2[12][0]                    \n",
      "                                                                 lstm_2[13][0]                    \n",
      "                                                                 lstm_2[14][0]                    \n",
      "                                                                 lstm_2[15][0]                    \n",
      "                                                                 lstm_2[16][0]                    \n",
      "                                                                 lstm_2[17][0]                    \n",
      "                                                                 lstm_2[18][0]                    \n",
      "                                                                 lstm_2[19][0]                    \n",
      "                                                                 lstm_2[20][0]                    \n",
      "                                                                 lstm_2[21][0]                    \n",
      "                                                                 lstm_2[22][0]                    \n",
      "                                                                 lstm_2[23][0]                    \n",
      "                                                                 lstm_2[24][0]                    \n",
      "                                                                 lstm_2[25][0]                    \n",
      "                                                                 lstm_2[26][0]                    \n",
      "                                                                 lstm_2[27][0]                    \n",
      "                                                                 lstm_2[28][0]                    \n",
      "                                                                 lstm_2[29][0]                    \n",
      "                                                                 lstm_2[30][0]                    \n",
      "                                                                 lstm_2[31][0]                    \n",
      "                                                                 lstm_2[32][0]                    \n",
      "                                                                 lstm_2[33][0]                    \n",
      "                                                                 lstm_2[34][0]                    \n",
      "                                                                 lstm_2[35][0]                    \n",
      "                                                                 lstm_2[36][0]                    \n",
      "                                                                 lstm_2[37][0]                    \n",
      "                                                                 lstm_2[38][0]                    \n",
      "                                                                 lstm_2[39][0]                    \n",
      "                                                                 lstm_2[40][0]                    \n",
      "                                                                 lstm_2[41][0]                    \n",
      "                                                                 lstm_2[42][0]                    \n",
      "                                                                 lstm_2[43][0]                    \n",
      "                                                                 lstm_2[44][0]                    \n",
      "                                                                 lstm_2[45][0]                    \n",
      "                                                                 lstm_2[46][0]                    \n",
      "                                                                 lstm_2[47][0]                    \n",
      "                                                                 lstm_2[48][0]                    \n",
      "                                                                 lstm_2[49][0]                    \n",
      "                                                                 lstm_2[50][0]                    \n",
      "                                                                 lstm_2[51][0]                    \n",
      "                                                                 lstm_2[52][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 54, 256)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[9][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[10][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[11][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[12][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[13][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[14][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[15][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[16][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[17][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[18][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[19][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[20][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[21][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[22][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[23][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[24][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[25][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[26][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[27][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[28][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[29][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[30][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[31][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[32][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[33][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[34][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[35][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[36][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[37][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[38][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[39][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[40][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[41][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[42][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[43][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[44][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[45][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[46][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[47][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[48][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[49][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[50][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[51][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[52][0]           \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[53][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 54, 10)       2570        concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 concatenate_1[9][0]              \n",
      "                                                                 concatenate_1[10][0]             \n",
      "                                                                 concatenate_1[11][0]             \n",
      "                                                                 concatenate_1[12][0]             \n",
      "                                                                 concatenate_1[13][0]             \n",
      "                                                                 concatenate_1[14][0]             \n",
      "                                                                 concatenate_1[15][0]             \n",
      "                                                                 concatenate_1[16][0]             \n",
      "                                                                 concatenate_1[17][0]             \n",
      "                                                                 concatenate_1[18][0]             \n",
      "                                                                 concatenate_1[19][0]             \n",
      "                                                                 concatenate_1[20][0]             \n",
      "                                                                 concatenate_1[21][0]             \n",
      "                                                                 concatenate_1[22][0]             \n",
      "                                                                 concatenate_1[23][0]             \n",
      "                                                                 concatenate_1[24][0]             \n",
      "                                                                 concatenate_1[25][0]             \n",
      "                                                                 concatenate_1[26][0]             \n",
      "                                                                 concatenate_1[27][0]             \n",
      "                                                                 concatenate_1[28][0]             \n",
      "                                                                 concatenate_1[29][0]             \n",
      "                                                                 concatenate_1[30][0]             \n",
      "                                                                 concatenate_1[31][0]             \n",
      "                                                                 concatenate_1[32][0]             \n",
      "                                                                 concatenate_1[33][0]             \n",
      "                                                                 concatenate_1[34][0]             \n",
      "                                                                 concatenate_1[35][0]             \n",
      "                                                                 concatenate_1[36][0]             \n",
      "                                                                 concatenate_1[37][0]             \n",
      "                                                                 concatenate_1[38][0]             \n",
      "                                                                 concatenate_1[39][0]             \n",
      "                                                                 concatenate_1[40][0]             \n",
      "                                                                 concatenate_1[41][0]             \n",
      "                                                                 concatenate_1[42][0]             \n",
      "                                                                 concatenate_1[43][0]             \n",
      "                                                                 concatenate_1[44][0]             \n",
      "                                                                 concatenate_1[45][0]             \n",
      "                                                                 concatenate_1[46][0]             \n",
      "                                                                 concatenate_1[47][0]             \n",
      "                                                                 concatenate_1[48][0]             \n",
      "                                                                 concatenate_1[49][0]             \n",
      "                                                                 concatenate_1[50][0]             \n",
      "                                                                 concatenate_1[51][0]             \n",
      "                                                                 concatenate_1[52][0]             \n",
      "                                                                 concatenate_1[53][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 54, 1)        11          dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "                                                                 dense_1[10][0]                   \n",
      "                                                                 dense_1[11][0]                   \n",
      "                                                                 dense_1[12][0]                   \n",
      "                                                                 dense_1[13][0]                   \n",
      "                                                                 dense_1[14][0]                   \n",
      "                                                                 dense_1[15][0]                   \n",
      "                                                                 dense_1[16][0]                   \n",
      "                                                                 dense_1[17][0]                   \n",
      "                                                                 dense_1[18][0]                   \n",
      "                                                                 dense_1[19][0]                   \n",
      "                                                                 dense_1[20][0]                   \n",
      "                                                                 dense_1[21][0]                   \n",
      "                                                                 dense_1[22][0]                   \n",
      "                                                                 dense_1[23][0]                   \n",
      "                                                                 dense_1[24][0]                   \n",
      "                                                                 dense_1[25][0]                   \n",
      "                                                                 dense_1[26][0]                   \n",
      "                                                                 dense_1[27][0]                   \n",
      "                                                                 dense_1[28][0]                   \n",
      "                                                                 dense_1[29][0]                   \n",
      "                                                                 dense_1[30][0]                   \n",
      "                                                                 dense_1[31][0]                   \n",
      "                                                                 dense_1[32][0]                   \n",
      "                                                                 dense_1[33][0]                   \n",
      "                                                                 dense_1[34][0]                   \n",
      "                                                                 dense_1[35][0]                   \n",
      "                                                                 dense_1[36][0]                   \n",
      "                                                                 dense_1[37][0]                   \n",
      "                                                                 dense_1[38][0]                   \n",
      "                                                                 dense_1[39][0]                   \n",
      "                                                                 dense_1[40][0]                   \n",
      "                                                                 dense_1[41][0]                   \n",
      "                                                                 dense_1[42][0]                   \n",
      "                                                                 dense_1[43][0]                   \n",
      "                                                                 dense_1[44][0]                   \n",
      "                                                                 dense_1[45][0]                   \n",
      "                                                                 dense_1[46][0]                   \n",
      "                                                                 dense_1[47][0]                   \n",
      "                                                                 dense_1[48][0]                   \n",
      "                                                                 dense_1[49][0]                   \n",
      "                                                                 dense_1[50][0]                   \n",
      "                                                                 dense_1[51][0]                   \n",
      "                                                                 dense_1[52][0]                   \n",
      "                                                                 dense_1[53][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 54, 1)        0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "                                                                 dense_2[10][0]                   \n",
      "                                                                 dense_2[11][0]                   \n",
      "                                                                 dense_2[12][0]                   \n",
      "                                                                 dense_2[13][0]                   \n",
      "                                                                 dense_2[14][0]                   \n",
      "                                                                 dense_2[15][0]                   \n",
      "                                                                 dense_2[16][0]                   \n",
      "                                                                 dense_2[17][0]                   \n",
      "                                                                 dense_2[18][0]                   \n",
      "                                                                 dense_2[19][0]                   \n",
      "                                                                 dense_2[20][0]                   \n",
      "                                                                 dense_2[21][0]                   \n",
      "                                                                 dense_2[22][0]                   \n",
      "                                                                 dense_2[23][0]                   \n",
      "                                                                 dense_2[24][0]                   \n",
      "                                                                 dense_2[25][0]                   \n",
      "                                                                 dense_2[26][0]                   \n",
      "                                                                 dense_2[27][0]                   \n",
      "                                                                 dense_2[28][0]                   \n",
      "                                                                 dense_2[29][0]                   \n",
      "                                                                 dense_2[30][0]                   \n",
      "                                                                 dense_2[31][0]                   \n",
      "                                                                 dense_2[32][0]                   \n",
      "                                                                 dense_2[33][0]                   \n",
      "                                                                 dense_2[34][0]                   \n",
      "                                                                 dense_2[35][0]                   \n",
      "                                                                 dense_2[36][0]                   \n",
      "                                                                 dense_2[37][0]                   \n",
      "                                                                 dense_2[38][0]                   \n",
      "                                                                 dense_2[39][0]                   \n",
      "                                                                 dense_2[40][0]                   \n",
      "                                                                 dense_2[41][0]                   \n",
      "                                                                 dense_2[42][0]                   \n",
      "                                                                 dense_2[43][0]                   \n",
      "                                                                 dense_2[44][0]                   \n",
      "                                                                 dense_2[45][0]                   \n",
      "                                                                 dense_2[46][0]                   \n",
      "                                                                 dense_2[47][0]                   \n",
      "                                                                 dense_2[48][0]                   \n",
      "                                                                 dense_2[49][0]                   \n",
      "                                                                 dense_2[50][0]                   \n",
      "                                                                 dense_2[51][0]                   \n",
      "                                                                 dense_2[52][0]                   \n",
      "                                                                 dense_2[53][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 128)       0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[10][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[11][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[12][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[13][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[14][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[15][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[16][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[17][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[18][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[19][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[20][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[21][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[22][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[23][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[24][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[25][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[26][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[27][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[28][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[29][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[30][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[31][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[32][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[33][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[34][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[35][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[36][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[37][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[38][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[39][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[40][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[41][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[42][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[43][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[44][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[45][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[46][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[47][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[48][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[49][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[50][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[51][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[52][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[53][0]         \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 128), (None, 131584      dot_1[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm_2[1][0]                     \n",
      "                                                                 lstm_2[1][2]                     \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm_2[2][0]                     \n",
      "                                                                 lstm_2[2][2]                     \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm_2[3][0]                     \n",
      "                                                                 lstm_2[3][2]                     \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm_2[4][0]                     \n",
      "                                                                 lstm_2[4][2]                     \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm_2[5][0]                     \n",
      "                                                                 lstm_2[5][2]                     \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm_2[6][0]                     \n",
      "                                                                 lstm_2[6][2]                     \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm_2[7][0]                     \n",
      "                                                                 lstm_2[7][2]                     \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm_2[8][0]                     \n",
      "                                                                 lstm_2[8][2]                     \n",
      "                                                                 dot_1[10][0]                     \n",
      "                                                                 lstm_2[9][0]                     \n",
      "                                                                 lstm_2[9][2]                     \n",
      "                                                                 dot_1[11][0]                     \n",
      "                                                                 lstm_2[10][0]                    \n",
      "                                                                 lstm_2[10][2]                    \n",
      "                                                                 dot_1[12][0]                     \n",
      "                                                                 lstm_2[11][0]                    \n",
      "                                                                 lstm_2[11][2]                    \n",
      "                                                                 dot_1[13][0]                     \n",
      "                                                                 lstm_2[12][0]                    \n",
      "                                                                 lstm_2[12][2]                    \n",
      "                                                                 dot_1[14][0]                     \n",
      "                                                                 lstm_2[13][0]                    \n",
      "                                                                 lstm_2[13][2]                    \n",
      "                                                                 dot_1[15][0]                     \n",
      "                                                                 lstm_2[14][0]                    \n",
      "                                                                 lstm_2[14][2]                    \n",
      "                                                                 dot_1[16][0]                     \n",
      "                                                                 lstm_2[15][0]                    \n",
      "                                                                 lstm_2[15][2]                    \n",
      "                                                                 dot_1[17][0]                     \n",
      "                                                                 lstm_2[16][0]                    \n",
      "                                                                 lstm_2[16][2]                    \n",
      "                                                                 dot_1[18][0]                     \n",
      "                                                                 lstm_2[17][0]                    \n",
      "                                                                 lstm_2[17][2]                    \n",
      "                                                                 dot_1[19][0]                     \n",
      "                                                                 lstm_2[18][0]                    \n",
      "                                                                 lstm_2[18][2]                    \n",
      "                                                                 dot_1[20][0]                     \n",
      "                                                                 lstm_2[19][0]                    \n",
      "                                                                 lstm_2[19][2]                    \n",
      "                                                                 dot_1[21][0]                     \n",
      "                                                                 lstm_2[20][0]                    \n",
      "                                                                 lstm_2[20][2]                    \n",
      "                                                                 dot_1[22][0]                     \n",
      "                                                                 lstm_2[21][0]                    \n",
      "                                                                 lstm_2[21][2]                    \n",
      "                                                                 dot_1[23][0]                     \n",
      "                                                                 lstm_2[22][0]                    \n",
      "                                                                 lstm_2[22][2]                    \n",
      "                                                                 dot_1[24][0]                     \n",
      "                                                                 lstm_2[23][0]                    \n",
      "                                                                 lstm_2[23][2]                    \n",
      "                                                                 dot_1[25][0]                     \n",
      "                                                                 lstm_2[24][0]                    \n",
      "                                                                 lstm_2[24][2]                    \n",
      "                                                                 dot_1[26][0]                     \n",
      "                                                                 lstm_2[25][0]                    \n",
      "                                                                 lstm_2[25][2]                    \n",
      "                                                                 dot_1[27][0]                     \n",
      "                                                                 lstm_2[26][0]                    \n",
      "                                                                 lstm_2[26][2]                    \n",
      "                                                                 dot_1[28][0]                     \n",
      "                                                                 lstm_2[27][0]                    \n",
      "                                                                 lstm_2[27][2]                    \n",
      "                                                                 dot_1[29][0]                     \n",
      "                                                                 lstm_2[28][0]                    \n",
      "                                                                 lstm_2[28][2]                    \n",
      "                                                                 dot_1[30][0]                     \n",
      "                                                                 lstm_2[29][0]                    \n",
      "                                                                 lstm_2[29][2]                    \n",
      "                                                                 dot_1[31][0]                     \n",
      "                                                                 lstm_2[30][0]                    \n",
      "                                                                 lstm_2[30][2]                    \n",
      "                                                                 dot_1[32][0]                     \n",
      "                                                                 lstm_2[31][0]                    \n",
      "                                                                 lstm_2[31][2]                    \n",
      "                                                                 dot_1[33][0]                     \n",
      "                                                                 lstm_2[32][0]                    \n",
      "                                                                 lstm_2[32][2]                    \n",
      "                                                                 dot_1[34][0]                     \n",
      "                                                                 lstm_2[33][0]                    \n",
      "                                                                 lstm_2[33][2]                    \n",
      "                                                                 dot_1[35][0]                     \n",
      "                                                                 lstm_2[34][0]                    \n",
      "                                                                 lstm_2[34][2]                    \n",
      "                                                                 dot_1[36][0]                     \n",
      "                                                                 lstm_2[35][0]                    \n",
      "                                                                 lstm_2[35][2]                    \n",
      "                                                                 dot_1[37][0]                     \n",
      "                                                                 lstm_2[36][0]                    \n",
      "                                                                 lstm_2[36][2]                    \n",
      "                                                                 dot_1[38][0]                     \n",
      "                                                                 lstm_2[37][0]                    \n",
      "                                                                 lstm_2[37][2]                    \n",
      "                                                                 dot_1[39][0]                     \n",
      "                                                                 lstm_2[38][0]                    \n",
      "                                                                 lstm_2[38][2]                    \n",
      "                                                                 dot_1[40][0]                     \n",
      "                                                                 lstm_2[39][0]                    \n",
      "                                                                 lstm_2[39][2]                    \n",
      "                                                                 dot_1[41][0]                     \n",
      "                                                                 lstm_2[40][0]                    \n",
      "                                                                 lstm_2[40][2]                    \n",
      "                                                                 dot_1[42][0]                     \n",
      "                                                                 lstm_2[41][0]                    \n",
      "                                                                 lstm_2[41][2]                    \n",
      "                                                                 dot_1[43][0]                     \n",
      "                                                                 lstm_2[42][0]                    \n",
      "                                                                 lstm_2[42][2]                    \n",
      "                                                                 dot_1[44][0]                     \n",
      "                                                                 lstm_2[43][0]                    \n",
      "                                                                 lstm_2[43][2]                    \n",
      "                                                                 dot_1[45][0]                     \n",
      "                                                                 lstm_2[44][0]                    \n",
      "                                                                 lstm_2[44][2]                    \n",
      "                                                                 dot_1[46][0]                     \n",
      "                                                                 lstm_2[45][0]                    \n",
      "                                                                 lstm_2[45][2]                    \n",
      "                                                                 dot_1[47][0]                     \n",
      "                                                                 lstm_2[46][0]                    \n",
      "                                                                 lstm_2[46][2]                    \n",
      "                                                                 dot_1[48][0]                     \n",
      "                                                                 lstm_2[47][0]                    \n",
      "                                                                 lstm_2[47][2]                    \n",
      "                                                                 dot_1[49][0]                     \n",
      "                                                                 lstm_2[48][0]                    \n",
      "                                                                 lstm_2[48][2]                    \n",
      "                                                                 dot_1[50][0]                     \n",
      "                                                                 lstm_2[49][0]                    \n",
      "                                                                 lstm_2[49][2]                    \n",
      "                                                                 dot_1[51][0]                     \n",
      "                                                                 lstm_2[50][0]                    \n",
      "                                                                 lstm_2[50][2]                    \n",
      "                                                                 dot_1[52][0]                     \n",
      "                                                                 lstm_2[51][0]                    \n",
      "                                                                 lstm_2[51][2]                    \n",
      "                                                                 dot_1[53][0]                     \n",
      "                                                                 lstm_2[52][0]                    \n",
      "                                                                 lstm_2[52][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           lstm_2[53][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            129         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 20,317,690\n",
      "Trainable params: 317,590\n",
      "Non-trainable params: 20,000,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, max_len, unknown_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = 60\n",
    "print(X_train.shape[0])\n",
    "print(X_train[train_index])\n",
    "print(X_train_indices[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((X_train.shape[0], 128))\n",
    "c0 = np.zeros((X_train.shape[0], 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([X_train_indices, s0, c0], Y_train, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len, unknown_word_index)\n",
    "s0 = np.zeros((X_test_indices.shape[0], 128))\n",
    "c0 = np.zeros((X_test_indices.shape[0], 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate([X_test_indices, s0, c0], Y_test)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len, unknown_word_index)\n",
    "pred = model.predict([X_test_indices, s0, c0])\n",
    "\n",
    "threshold = 0.5\n",
    "Y_pred = pred > threshold\n",
    "\n",
    "\n",
    "error_count = 0;\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    if(Y_pred[i] != Y_test[i]):\n",
    "        error_count = error_count + 1\n",
    "        print( str(i) + ' : ' + X_test[i])\n",
    "        print('Expected label:'+ str(Y_test[i]) + ' Prediction: ' + ' ' + str( 1 if Y_pred[i] else 0))\n",
    "print('Test count : ' + str(len(X_test)))\n",
    "print('Error count : ' + str(error_count))\n",
    "\n",
    "print('F1 Score for Trolling: ', f1_score(Y_test, Y_pred))\n",
    "\n",
    "Y_test_inv = np.invert(Y_test > 0).reshape(-1,1)\n",
    "Y_pred_inv = np.invert(Y_pred).reshape(-1,1)\n",
    "\n",
    "print('Constructive feedback count : ', np.sum(Y_test_inv))\n",
    "print('Predicted Constructive feedback count : ', np.sum(Y_pred_inv))\n",
    "print('F1 Score Constructive Feedback: ', f1_score(Y_test_inv, Y_pred_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = 0;\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    if(Y_pred[i] == Y_test[i]):\n",
    "        print(X_test_indices[i])\n",
    "        correct_count = correct_count + 1\n",
    "        print( str(i) + ' : ' + X_test[i])\n",
    "        print('Expected label:'+ str(Y_test[i]) + ' Prediction: ' + ' ' + str(Y_pred[i]))\n",
    "print('Test count : ' + str(len(X_test)))\n",
    "print('Error count : ' + str(correct_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to visualize the attention weights at the last time-step of the second LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_map(model, X_test_indices, X_test, n_s = 128, num = 6, Tx = 30):\n",
    "    \"\"\"\n",
    "    Plot the attention map.\n",
    "  \n",
    "    \"\"\"\n",
    "    attention_map = np.zeros((Tx, Tx))\n",
    "    Ty, Tx = attention_map.shape\n",
    "    \n",
    "    s0 = np.zeros((1, n_s))\n",
    "    c0 = np.zeros((1, n_s))\n",
    "    layer = model.layers[num]\n",
    "    print(layer.name)\n",
    "\n",
    "    f = K.function(model.inputs, [layer.get_output_at(t) for t in range(Tx)])\n",
    "    r = f([X_test_indices, s0, c0])\n",
    "    \n",
    "    for t in range(Tx):\n",
    "        for t_prime in range(Tx):\n",
    "            attention_map[t][t_prime] = r[t][0,t_prime,0]\n",
    "\n",
    "    # Normalize attention map\n",
    "#     row_max = attention_map.max(axis=1)\n",
    "#     attention_map = attention_map / row_max[:, None]\n",
    "\n",
    "    prediction = model.predict([X_test_indices, s0, c0])\n",
    "    \n",
    "    Y_prediction = prediction > threshold\n",
    "    predicted_text = []\n",
    "   # for i in range(len(prediction)):\n",
    "  #      predicted_text.append(int(np.argmax(prediction[i], axis=1)))\n",
    "        \n",
    "    #predicted_text = list(predicted_text)\n",
    "   # predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n",
    "    text_ = X_test.lower().split()\n",
    "    \n",
    "    # get the lengths of the string\n",
    "    input_length = len(text_)\n",
    "    output_length = Tx\n",
    "    \n",
    "    # Plot the attention_map\n",
    "    plt.clf()\n",
    "    f = plt.figure(figsize=(25, 25.5))\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "    # add image\n",
    "    i = ax.imshow(attention_map, interpolation='nearest', cmap='Blues')\n",
    "\n",
    "    # add colorbar\n",
    "    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
    "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
    "    cbar.ax.set_xlabel('Alpha value (Probability output of the \"softmax\")', labelpad=2)\n",
    "\n",
    "    # add labels\n",
    "  #  ax.set_yticks(range(output_length))\n",
    "  #  ax.set_yticklabels(predicted_text[:output_length])\n",
    "\n",
    "    ax.set_xticks(range(input_length))\n",
    "    ax.set_xticklabels(text_[:input_length], rotation='60')\n",
    "\n",
    "    ax.set_xlabel('Input Sequence')\n",
    "    ax.set_ylabel('Output Sequence')\n",
    "\n",
    "    # add grid and legend\n",
    "    ax.grid()\n",
    "\n",
    "    #f.show()\n",
    "    \n",
    "    return attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1836 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attention_map(model, X_test_indices[1].reshape(1,54), X_test[1], n_s = 128, num = 8, Tx = Tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"../models/model.json\", \"w\") as json_file:\n",
    "    print('works')\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"../models/model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model = coremltools.converters.keras.convert(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model.save('../models/CommentNetV2.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coreml_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sisira Dabare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
